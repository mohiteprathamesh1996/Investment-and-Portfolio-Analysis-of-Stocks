{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from textblob import TextBlob\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "# from sys import\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_yahoo(search_term):\n",
    "    pn = 1\n",
    "    l = []\n",
    "    t = []\n",
    "\n",
    "    for lkd in range(5):\n",
    "        url = \"https://news.search.yahoo.com/search?q={}&pz=10&b={}\".format(search_term, pn)\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        headlines = soup.find_all(\"div\")\n",
    "\n",
    "        d = []\n",
    "        for h in headlines:\n",
    "            d.append(TextBlob(h.get_text()))\n",
    "\n",
    "\n",
    "        for i in range(len(d[0].split(\"...\")[:-1])):\n",
    "            try:\n",
    "                ind = [[i.start(),i.end()] for i in re.finditer(re.compile(\"|\".join([\"\\d+\\s*(?:year|years)\\s*ago\",\n",
    "                                                                                     \"\\d+\\s*(?:day|days)\\s*ago\",\n",
    "                                                                                     \"\\d+\\s*(?:hour|hours)\\s*ago\",\n",
    "                                                                                     \"\\d+\\s*(?:minute|minute)\\s*ago\",\n",
    "                                                                                     \"\\d+\\s*(?:seconds|seconds)\\s*ago\",\n",
    "                                                                                     \"Local\\s*Answers\\s*Shopping\\s*More\"])), \n",
    "                                                                d[0].split(\"...\")[i])]\n",
    "                timings = re.findall(re.compile(\"|\".join([\"\\d+\\s*(?:year|years)\\s*ago\",\n",
    "                                                          \"\\d+\\s*(?:day|days)\\s*ago\",\n",
    "                                                          \"\\d+\\s*(?:hour|hours)\\s*ago\",\n",
    "                                                          \"\\d+\\s*(?:minute|minute)\\s*ago\",\n",
    "                                                          \"\\d+\\s*(?:seconds|seconds)\\s*ago\"])), \n",
    "                                                                d[0].split(\"...\")[i])\n",
    "                if i==0:\n",
    "                    l.append((d[0].split(\"...\")[i][ind[0][1] : ind[1][0]], timings[0]))\n",
    "    #                 t.append(timings[0])\n",
    "                else:\n",
    "                    l.append((d[0].split(\"...\")[i][:ind[0][0]], timings[0]))\n",
    "    #                 t.append(timings[0])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        pn = pn + 10\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame(l, columns=[\"News\",\"Timing\"])\n",
    "\n",
    "    df[\"Date\"] = np.nan\n",
    "    for i in range(len(df[\"Timing\"])):\n",
    "        if \"day\" in df[\"Timing\"][i]:\n",
    "            df[\"Date\"][i] = datetime.datetime.now()-datetime.timedelta(days=int(re.findall(re.compile(\"(\\d+)\"),\n",
    "                                                                                         df[\"Timing\"][i])[0]))\n",
    "        elif \"hour\" in df[\"Timing\"][i]:\n",
    "            df[\"Date\"][i] = datetime.datetime.now()-datetime.timedelta(hours=int(re.findall(re.compile(\"(\\d+)\"),\n",
    "                                                                                          df[\"Timing\"][i])[0]))\n",
    "\n",
    "    df = df.sort_values(by=[\"Date\"], ascending=False).reset_index(drop=True)\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    df[\"Compounded_Polarity\"] = [vader.polarity_scores(k)[\"compound\"] for k in df[\"News\"]]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
